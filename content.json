{"meta":{"title":"Binge.van","subtitle":null,"description":"点滴积累","author":"范斌","url":"http://github.com/Bingevan","root":"/Bingevan/"},"pages":[{"title":"Me","date":"2019-03-15T10:50:36.000Z","updated":"2019-03-15T13:25:26.514Z","comments":true,"path":"about/index.html","permalink":"http://github.com/Bingevan/about/index.html","excerpt":"","text":"水滴石穿，积少成多！"},{"title":"标签","date":"2019-03-12T04:06:44.000Z","updated":"2019-03-12T04:11:05.079Z","comments":true,"path":"tags/index.html","permalink":"http://github.com/Bingevan/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2019-03-12T04:12:00.000Z","updated":"2019-03-12T04:13:17.141Z","comments":true,"path":"categories/index.html","permalink":"http://github.com/Bingevan/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"MobileNetV1","slug":"MobileNetV1","date":"2019-05-10T06:10:18.000Z","updated":"2019-05-15T11:51:15.565Z","comments":true,"path":"2019/05/10/MobileNetV1/","link":"","permalink":"http://github.com/Bingevan/2019/05/10/MobileNetV1/","excerpt":"","text":"MobileNetV1 《MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications 》 The paper address：https://arxiv.org/abs/1704.04861 The coding address：https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.py WWH（What&amp;Why&amp;How）​ MobileNet描述了一个高效的网络架构，可以构建一个非常小、低延时、满足嵌入式设备的要求。模型的大小显著下降，但是实际效果很好。 Innovation Points 深度可分离卷积（Depthwise Separable Convolution） 宽度因子（Width Multiplier）&amp; 分辨率因子（Resolution Multiplier） Depthwise Separable Convolution 深度可分离卷积：将普通卷积分成深度卷积（DW）与逐点卷积（PW），这样做可大幅度降低参数量与计算量。 问题描述 Depthwise Separable Convolution与普通卷积的输入与输出均相同，中间过程不同。 输入： ，其中 为原始图片尺寸， 为输入channel数量。 输出： ，其中 为输出图片尺寸， 为输出channel数量。 普通卷积 卷积核： 卷积核如下图所示： 深度可分离卷积深度卷积 输入： ，输出 卷积核：M个 。 理解： 将特征图看成是M张二维的特征图即M张 的特征图 将M张特征图分别与 的卷积核卷积 也就是对channel进行分解 逐点卷积 输入 ，输出 。 卷积核： 。 计算量对比分子为Depthwise Separable卷积，分母为普通卷积。 深度可分离卷积与标准卷积相比：当采用3x3的卷积核，计算量可以减少9倍左右 结构 注意：如果是需要下采样，则在第一个深度卷积上取步长为2. 实现代码1234567891011121314151617class Block(nn.Module): '''Depthwise conv + Pointwise conv''' def __init__(self, in_planes, out_planes, stride=1): super(Block, self).__init__() self.conv1 = nn.Conv2d\\ (in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False) self.bn1 = nn.BatchNorm2d(in_planes) self.conv2 = nn.Conv2d\\ (in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False) self.bn2 = nn.BatchNorm2d(out_planes) def forward(self, x): out = F.relu(self.bn1(self.conv1(x))) out = F.relu(self.bn2(self.conv2(out))) return out MobileNetV1网络网络结构 网络介绍 MobileNet优化的重点放在优化延迟(latency)，兼顾模型大小。 网络参数、计算量分布： MobileNet中大多数计算量和参数都在1*1的卷积中，可以使用高度优化的。 由于模型较小，所以可以减少使用正则化，因为模型小不容易过拟合。 Width Multiplier&amp;Resolution MultiplierWidth Multiplier, ： 用于控制输入和输出的通道数，即输入通道从M 变为αM ,输出通道从N变为αN。 对于depthwise卷积操作，其计算量为： 可设置α∈(0,1]，通常取1,0.75,0.5和0.25 。 Resolution Multiplier， 用于控制输入和内部层表示。即用分辨率因子控制输入的分辨率，该参数用于控制特征图的宽和高 。 对于depthwise卷积操作，其计算量为： 可设置ρ∈(0,1]，通常设置输入分辨率为224,192,160和128","categories":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"http://github.com/Bingevan/categories/计算机视觉/"}],"tags":[]},{"title":"MobileNetV2","slug":"MobileNetV2","date":"2019-05-10T06:10:18.000Z","updated":"2019-05-15T11:58:02.319Z","comments":true,"path":"2019/05/10/MobileNetV2/","link":"","permalink":"http://github.com/Bingevan/2019/05/10/MobileNetV2/","excerpt":"","text":"MobileNetV2 《Inverted Residuals and Linear Bottlenecks Mobile Networks for Classification, Detection and Segmentation 》 The paper address：https://128.84.21.199/abs/1801.04381 The coding address：https://github.com/miraclewkf/MobileNetV2-PyTorch WWH（What&amp;Why&amp;How）​ MobileNetV2是对MobileNetV1的改进，同样式轻量级的神经网络。实现了分类/目标检测/语义分割对目标任务，将MobileNetV2作为SSD的基础网络设计目标检测模型SSDLite。可以使参数降低一个数量级，但是mPA无明显变化。 ​ MobileNet-V1 最大的特点就是采用depth-wise separable convolution来减少运算量以及参数量，而在网络结构上，没有采用shortcut的方式。 ResNet及DenseNet等一系列采用shortcut的网络的成功，表明了shortcut是个非常好的东西，作者希望引入shortcut到MobileNet中。但是将residual block运用到depth-wise separable convolution，会碰到如下两个问题： DWConv layer 提取特征限制于输入特征维度，若采用residual block，1x1 PW conv操作后会先将输入特征图压缩(一般压缩率为0.25)，再经行DW conv后提取的特征或更少。MobileNetV2是先经过1x1 的PW conv操作将特征图扩张（本文扩大6倍），这也就可以不受输入通道的限制，可以提取更多的特征。 深度可分离卷积的PW conv相对于是对上一层DWconv的压缩，PWconv后跟随的是ReLU，根据ReLU的性质，输入特征若为负数，经过激活层输入的特征全是0，本来特征已经经过压缩，这会进一步损失特征值；若输入特征是正数，经过激活层输出特征是还原始的输入值。根据这一特点改变激活函数用Linear bottlenecks 代替。 Innovation Points Inverted residuals Linear Bottlenecks Inverted residuals​ Inverted residuals，通常的residuals block是先经过一个1x1的Conv layer，把feature map的通道数“压”下来，再经过3x3 Conv layer，最后经过一个1x1 的Conv layer，将feature map 通道数再“扩张”回去。即先“压缩”，最后“扩张”回去。 而 inverted residuals就是 先“扩张”，最后“压缩”。如下图所示。 ​ inverted residuals 可以认为是 residual block 的拓展。在 0&lt;t&lt;1，其实就是标准的残差模块。论文中 t 大部分为 6，呈现梭子的外形，而传统残差设计是沙漏形状。 Linear Bottlenecks​ 为了避免ReLU对特征的破坏，在residual block sum之前的PW conv后的激活层该成Linear Bottlenecks。在MobileNet V1中除了引入depthwise separable convolution代替传统的卷积，还做了一个实验是用width multiplier参数来做模型通道的缩减，相当于给模型“瘦身”，这样特征信息就能更集中在缩减后的通道中，但是如果此时加上一个非线性激活层，比如ReLU，就会有较大的信息丢失，因此为了减少信息丢失，就有了文中的linear bottleneck，意思就是bottleneck的输出不接非线性激活层，所以是linear，原因是： 对于ReLU层输出的非零值而言，ReLU层起到的就是一个线性变换的作用，这个从ReLU的曲线就能看出来。 ReLU层可以保留input manifold的信息，但是只有当input manifold是输入空间的一个低维子空间时才有效。 ​ 作者经过实验证明：当把原始输入维度增加到15或30后再作为ReLU的输入，输出恢复到原始维度后基本不会丢失太多的输入信息；相比之下如果原始输入维度只增加到2或3后再作为ReLU的输入，输出恢复到原始维度后信息丢失较多。因此在MobileNet V2中，执行降维的卷积层后面不会接类似ReLU这样的非线性激活层，也就是linear bottleneck的含义。 比较MobileNetV1和MobileNetV2的区别： 1、相同点： ​ 都采用 Depth-wise (DW) 卷积搭配 Point-wise (PW) 卷积的方式来提特征。这两个操作合起来也被称为 Depth-wise Separable Convolution，之前在 Xception 中被广泛使用。这么做的好处是理论上可以成倍的减少卷积层的时间复杂度和空间复杂度。标准卷积的计算复杂度近似为 DW + PW 组合卷积的 K^2倍。 2、不同点：（Linear Bottleneck） V2 在 DW 卷积之前新加了一个 PW 卷积。这么做的原因，是因为 DW 卷积由于本身的计算特性决定它自己没有改变通道数的能力，上一层给它多少通道，它就只能输出多少通道。所以如果上一层给的通道数本身很少的话，DW 也只能很委屈的在低维空间提特征，因此效果不够好。现在 V2 为了改善这个问题，给每个 DW 之前都配备了一个 PW，专门用来升维，定义升维系数6 ，这样不管输入通道数C_in 是多是少，经过第一个 PW 升维之后，DW 都是在相对的更高维进行着辛勤工作的。 V2 去掉了第二个 PW 的激活函数。论文作者称其为 Linear Bottleneck。这么做的原因，是因为作者认为激活函数在高维空间能够有效的增加非线性，而在低维空间时则会破坏特征，不如线性的效果好。由于第二个 PW 的主要功能就是降维，因此按照上面的理论，降维之后就不宜再使用 ReLU6 了。 精度对比如下图。 ResNet和MobileNet-V2的对比 1、相同点： （1）MobileNet V2 借鉴 ResNet，都采用了 的模式。 （2）MobileNet V2 借鉴 ResNet，同样使用 Shortcut 将输出与输入相加（未在上式画出） 2、不同点：（Inverted Residual Block） ResNet 使用 标准卷积 提特征，MobileNet 始终使用 DW卷积 提特征。 ResNet 先降维 (0.25倍)、卷积、再升维，而 MobileNet V2 则是 先升维 (6倍)、卷积、再降维。直观的形象上来看，ResNet 的微结构是沙漏形，而 MobileNet V2 则是纺锤形，刚好相反。因此论文作者将 MobileNet V2 的结构称为 Inverted Residual Block。这么做也是因为使用DW卷积而作的适配，希望特征提取能够在高维进行。 精度对比图。 网络结构​ 论文提出的 MobileNetV2 模型结构容易理解，基本单元 bottleneck 就是 Inverted residuals 模块，所用到的 tricks 比如 Dwise，就是 Depthwise Separable Convolutions，即各通道分别卷积。表 3 所示的分类网络结构输入图像分辨率 224x224，输出是全卷积而非 softmax，k 就是识别目标的类别数目。 ​ MobileNetV2 的网络结构中，第 6 行 stride=2，会导致下面通道分辨率变成14x14，从表格看，这个一处应该有误。 ​ 特别的，针对stride=1 和stride=2，在block上有稍微不同，主要是为了与shortcut的维度匹配，因此，stride=2时，不采用shortcut。 具体如下图：","categories":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"http://github.com/Bingevan/categories/计算机视觉/"}],"tags":[]},{"title":"","slug":"数据清洗","date":"2019-03-17T08:12:40.000Z","updated":"2019-03-17T08:31:16.156Z","comments":true,"path":"2019/03/17/数据清洗/","link":"","permalink":"http://github.com/Bingevan/2019/03/17/数据清洗/","excerpt":"","text":"数据清洗预处理工具 关系型数据库或者Python 元数据与数据的特征查看 对数据有直观的了解，位置后的数据处理做准备 缺省值清洗 确定缺省值的范围 去除不需要的字段 填充缺省值内容（重要 ） 重新获取数据","categories":[{"name":"面试","slug":"面试","permalink":"http://github.com/Bingevan/categories/面试/"},{"name":"机器学习","slug":"面试/机器学习","permalink":"http://github.com/Bingevan/categories/面试/机器学习/"}],"tags":[]},{"title":"","slug":"A机器学习总结/数据清洗","date":"2019-03-17T08:12:40.000Z","updated":"2019-05-15T14:18:54.915Z","comments":true,"path":"2019/03/17/A机器学习总结/数据清洗/","link":"","permalink":"http://github.com/Bingevan/2019/03/17/A机器学习总结/数据清洗/","excerpt":"","text":"数据清洗预处理工具 关系型数据库或者Python 元数据与数据的特征查看 对数据有直观的了解，位置后的数据处理做准备 缺省值清洗 确定缺省值的范围 去除不需要的字段 填充缺省值内容（重要 ） 重新获取数据","categories":[{"name":"面试","slug":"面试","permalink":"http://github.com/Bingevan/categories/面试/"},{"name":"机器学习","slug":"面试/机器学习","permalink":"http://github.com/Bingevan/categories/面试/机器学习/"}],"tags":[]},{"title":"改进快速排序","slug":"01快速排序","date":"2019-03-17T02:00:51.000Z","updated":"2019-03-18T12:26:56.541Z","comments":true,"path":"2019/03/17/01快速排序/","link":"","permalink":"http://github.com/Bingevan/2019/03/17/01快速排序/","excerpt":"","text":"##partition算法 （荷兰国旗问题）给定一个数组arr，和一个数num，请把小于num的数放在数组的左边，等于num的数放在数组的中间，大于num的数放在数组的右边。要求额外空间复杂度O(1)，时间复杂度O(N) 思想： 大于num的数放在数组的左边，小于num的数放在数组的右边，设当前指针为cur，小于区域的最后一个数指针为less，大于区域的第一个数为more。 解题： 要比较的数x=num，cur+1； 要比较的数x&lt;num,x与小于区域的下一个数交换，并且cur+1、less+1 要比较的数x&gt;num,x与大于区域的前一个数交换，并且more+1 代码： 123456789101112131415161718192021public static int[] pattena(int[] arr,int L,int R,int num)&#123; int less = L-1; int more = R+1; int cur = L; while (cur&lt;more)&#123; if(arr[cur]&lt;num)&#123; awap(arr,++less,cur++); &#125;else if(arr[cur]&gt;num)&#123; awap(arr,cur,--more); &#125;else &#123; cur++; &#125; &#125; //return new int[]&#123;less+1,more-1&#125;; return arr; &#125;public static void awap(int[] arr,int i ,int j)&#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp;&#125; 基于partition改进后的快速排序 随机快速排序的细节和复杂度分析可以用荷兰国旗问题来改进快速排序时间复杂度O(N*logN)，额外空间复杂度O(logN) 解题： 将数组的最后一个数最为num 小于num的放在左边，—&gt; 递归 大于num的放在右边，—&gt; 递归 代码实现： 12345678910111213141516171819202122232425262728293031public static int[] quickSort(int arr[],int L, int R) &#123; if(L&lt;R) &#123; int num = arr[arr.length - 1]; int[] idnex = partition(arr, L, R,num); quickSort(arr, L, idnex[0]-1); quickSort(arr, idnex[1]+1, R); &#125; return arr; &#125;public static int[] partition(int[] arr,int L,int R,int num)&#123; int less = L-1; int more = R; int cur = L; while (cur &lt; more) &#123; if (arr[cur]&lt;num) &#123; exchange(arr,++less,cur++); &#125; else if (arr[cur]&gt;num) &#123; exchange(arr,--more, cur); &#125;else &#123; cur++; &#125; &#125; exchange(arr, more, R); return new int[]&#123;less + 1, more &#125;;&#125;public static void exchange(int[] arr,int i, int j) &#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp;&#125;","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://github.com/Bingevan/categories/数据结构/"}],"tags":[]},{"title":"深度学习基础","slug":"深度学习","date":"2019-03-17T02:00:51.000Z","updated":"2019-03-18T11:43:23.621Z","comments":true,"path":"2019/03/17/深度学习/","link":"","permalink":"http://github.com/Bingevan/2019/03/17/深度学习/","excerpt":"","text":"过拟合与欠拟合 欠拟合：指模型不能在训练数据集上获得足够低的训练误差 过拟合：指模型的训练误差与测试误差（泛化误差）上的误差过大 反映在评价指标上就是模型在训练集上表现良好，但是在测试集或者在新数据集上的表现一般（泛化能力差） 降低过拟合风险的方法 所有为了减小测试误差的策略统称为正则化方法，这些方法可能会议增大训练误差为代价。 数据增强 图像：平移、旋转、缩放 利用生成对抗网络生成新数据 NLP：利用机器翻译生成新数据 降低模型复杂度 神经网络：减少网络层、神经元个数 决策树：降低树的深度、剪枝 权值约束（添加正则化项） L1、L2正则化 集成学习 神经网络：Dropout 决策树：随机森林、GDBT 提前终止 降低欠拟合风险的方法 加入新的特征 交叉特征、多项式特征 升读学习：因子分解机、Deep-Crossing 增加模型复杂度 线性模型：添加高次项 神经网络：增加网络层数、神经元个数 减小正则化项的系数 添加正则化项是为了限制模型的学习能力，减小正则化项可以放宽这个限制 模型通常更加倾向于更大的权重，更大的权重可以使模型更好的拟合 反向传播算法反向传播的作用、目的、本质 概述：梯度下降法中需要利用损失函数对所有参数的梯度来寻找局部最小点，而反向传播算法就是用于计算梯度的算法，其本质就是利用链式求导法则对每个参数求偏导。 公式推导https://blog.csdn.net/lien0906/article/details/79193103 激活函数激活函数的作用——为什么使用非线性激活函数使用非线性激活函数的目的是为了像网络中加入非线性因素；增强网络的表示能力，解决线性网络存在的问题。 为什么加入非线性网络可以增强网络的表达能力呢——神经网络的万能近似定理 神经网络的万能近似定理认为震惊网络具有至少一个非线性隐含层，那么只要给网络足够数量的隐藏单元，他就可以以任意的精度来近似任何从一个有限维空间到另一个有限维空间的函数。 如果不使用非线性激活函数，那么每一层输出都是上一层输入的线性组合；此时无论网络有多少层，其整体也将是线性的，这会导致失去万能近似的性质。 但是部分层是纯线性是可以接受的，有助于减少网络的参数。 常见的激活函数整流线性单元ReLU ReLU通常是激活函数最好的默认选择 =\\max(0,z)) ReLU的拓展 ReLU及其扩展都是基于以下公式： 绝对值整流（absolute value rectification） 当a=-1，此时函数就是g(z)=|z| 渗漏整流线性单元 当a是一个很小的值，如a=0.001 参数化线性整流 将a作为一个可学习的参数 maxout单元 maxout单元进一步扩展了ReLU，他是一个可学习的K段函数，参数数量是普通全连接层的 k 倍 。 ####sigmoid与tanh sigmoid(z)，常记作 σ(z)； tanh(z) 的图像与 sigmoid(z) 大致相同，区别是值域为 (-1, 1) =\\frac{1}{1+\\exp(-z)}) 其他激活函数ReLU（优势）与sigmoid比较1.避免梯度消失 sigmoid函数在输入取绝对值非常大的正值或者负值的时候会出现饱和现象——在图像上表现的很平，此时函数会对输入的微小变化不敏感——从而造成梯度消失 ReLU的导数始终是一个常数——负半区为0，正半区为1，——所以不会发生梯度消失 2.减缓过拟合 ReLU在负半区输出为0，一旦神经元的激活值进入负半轴，那么该机或值就不会产生梯度/不会被训练，造成了网络的稀疏性——稀疏激活。 有利于减少参数的相互依赖，缓解过拟合问题的发生。 3.加速计算 ReLU的求导不涉及浮点运算 为什么 ReLU 不是全程可微/可导也能用于基于梯度的学习？ 在实现过程中通常返回左导数或者右导数的其中一个。 正则化Batch Normalizaton(批标准化) BN是一种正则化方法（较少泛化误差），主要的作用有： 加速网络的训练（缓解梯度消失，支持更大的学习率） 防止过拟合 降低参数初始化的要求 动机： 训练的本质就是学习数据的分布。如果训练数据与测试数据分布不同会降低模型的泛化能力，因此应该在训练前对所有输入数据做归一化处理。 在神经网络中，因为每个隐层的参数不同，会使下一层的输入发生变化，从而导致每一批数据的分布也发生变化，从而导致网络在每次迭代中需要拟合不同的数据分布，增加了网络的训练难度与过拟合的风险。 基本原理 BN方法会正对每一批数据，在网络的每一层输入之前增加归一化处理，是输入的均值为0，标准差为1，目的是将数据限制在统一的分布下。 具体就是，针对每一层的K个神经元，计算这一批数据在低K个神经元的均值与标准差，然后将归一化的值作为该神经元的激活函值。 BN可以看作在各层之间加入了一个新的计算层，对数据进行额外的约束，从而增加模型的泛化能力 但是BN也降低了模型的拟合能力，破坏了之前学习到的特征分布。 为了恢复原式的数据，BN引入了一个重构变化来还原最优的输入数据的分布 其中 γ 和 β 为可训练参数。 小结： 以上过程可归纳为一个 BN(x) 函数： ) 其中 &amp;=\\gamma\\boldsymbol{\\hat{x}_i}+\\beta\\&space;&amp;=\\gamma\\frac{\\boldsymbol{x_i}-\\boldsymbol{\\mathrm{E}[x_i]}}{\\sqrt{\\boldsymbol{\\mathrm{Var}[x_i]}+\\epsilon}}+\\beta&space;\\end{aligned}) 完整算法： L1/L2 范数正则化L1/L2范数的作用、异同相同点：限制了模型的学习能力——通过限制模型参数的规模，使模型偏好于权值较小的目标函数，防止过拟合。 不同点： L1正则化可以产生稀疏的权值举证，可以用于特征选择，同时一定程度上防止过拟合；L2正则化用于防止模型过拟合 L1正则化适用于特征之间有关联的情况；L2正则化适用于特征之间没有关联的情况。 为什么L1和L2正则化可以防止过拟合 L1、L2正则化回事模型偏好于更小的权重 更小的权重意味着更低的模型复杂度，添加L1和L2正则化相当于为模型添加了某种先验，限制参数的分布，从而降低了模型的复杂度。 模型的复杂度低意味着模型对于噪声与异常点的抗干扰能力增强，从而提高了模型的泛化能力——直观来说就是对训练数据的拟合刚刚号，不会过分拟合数据——奥卡姆剃刀定理 为什么L1正则化可以产生稀疏的权值，L2不会？ 对于目标函数添加范数正则化，训练时相当于在范数的约束下求目标函数J的最小值 带有L1 范数（左）和L2 范数（右）约束的二维图示 图中 J 与 L1 首次相交的点即是最优解。L1 在和每个坐标轴相交的地方都会有“顶点”出现，多维的情况下，这些顶点会更多；在顶点的位置就会产生稀疏的解。而 J 与这些“顶点”相交的机会远大于其他点，因此 L1 正则化会产生稀疏的解。 L2 不会产生“顶点”，因此 J 与 L2 相交的点具有稀疏性的概率就会变得非常小。 DropoutBagging集成学习 集成方法的主要想法是分别训练不同的模型，然后让所有的模型表决最终的输出。 集成学习凑效的原因是不同模型通常不会在测试集上产生相同的误差。 集成模型能至少与它的任何一成员 表现的一样好。如果成员的误差是独立的，集成将显著提升模型的性能。 Bagging是一种集成学习的策略——具体来说，Bagging涉及构造K个不同的数据集 每个数据集从原始数据集中重复采样构成，和原始数据集具有相同的样例，——这就意味着每个数据集有大概率缺少来自原始数据集的例子，但是也包含若干重复的例子 更具体的就是，如果采样所得到的训练集与原式的数据集大小相同，那么所得到的数据集中大概有原始数据集2/3的实例。 集成算法与神经网络 神经网络能够找到足够多的不同的解，意味着他们可以从模型平均中受益——即使所有的模型都在同一数据集上训练。 神经网络中随机初始化的差异、批训练数据的随机选择、超参数的差异等非确定性实现往往足以使得继承中的不同成员有部分独立的误差。 Dropout策略 简单来说，Dropout是通过共享参数提供了一种廉价的Bagging集成近似——Drpout相当于继承了从基础网络去除部分单元后形成的子网络。 通常隐层的采样率为0.5,输入的采样率为0.8，超参数也可以这样，但其采样率一般为1 权重比例推断规则 权重比例推断规则的目的是确保在测试时一个单元的期望总输入与在训练时该单元的期望总输入大致相同。 实践时，如果使用 0.5 的采样概率，权重比例规则相当于在训练结束后将权重乘 0.5，然后像平常一样使用模型；等价的，另一种方法是在训练时将单元的状态乘 2。 Dropout 与 Bagging 的不同 在 Bagging 的情况下，所有模型都是独立的；而在 Dropout 的情况下，所有模型共享参数，其中每个模型继承父神经网络参数的不同子集。 在 Bagging 的情况下，每一个模型都会在其相应训练集上训练到收敛。而在 Dropout 的情况下，通常大部分模型都没有显式地被训练；取而代之的是，在单个步骤中我们训练一小部分的子网络，参数共享会使得剩余的子网络也能有好的参数设定。","categories":[{"name":"面试","slug":"面试","permalink":"http://github.com/Bingevan/categories/面试/"}],"tags":[]},{"title":"CBAM","slug":"CBAM网络","date":"2019-03-16T06:10:18.000Z","updated":"2019-05-15T12:10:01.580Z","comments":true,"path":"2019/03/16/CBAM网络/","link":"","permalink":"http://github.com/Bingevan/2019/03/16/CBAM网络/","excerpt":"摘要 CBAM特点就是轻量级通用模块 可以很好的加入到CNN结构中 端到端可训练的CNNs","text":"摘要 CBAM特点就是轻量级通用模块 可以很好的加入到CNN结构中 端到端可训练的CNNs 作者贡献 提出了一个高效的attention模块—-CBAM，该模块能够嵌入到目前的主流CNN网络结构中。 通过额外的分离实验证明了CBAM中attention的有效性。 在多个平台上（ImageNet-1K，MS COCO和VOC 2007）上证明了CBAM的性能提升。 Convolutional Block Attention Module给定输入特征为 对于一个中间层的feature map：，CBAM将会顺序推理出1维的channel attention map 以及2维的spatial attention map ，整个过程如下所示： %20%5Cotimes%20F) %20%5Cotimes%20F%5E%7B%27%7D) 其中为element-wise multiplication，首先将channel attention map与输入的feature map相乘得到，之后计算的spatial attention map，并将两者相乘得到最终的输出。下图为CBAM的示意图： Channel attention moduleeature map 的每个channel都被视为一个feature detector，channel attention主要关注于输入图片中什么(what)是有意义的。为了高效地计算channel attention，论文使用最大池化和平均池化对feature map在空间维度上进行压缩，得到两个不同的空间背景描述：和。使用由MLP组成的共享网络对这两个不同的空间背景描述进行计算得到channel attention map：。计算过程如下： 其中，，后使用了Relu作为激活函数。 Spatial attention module. 与channel attention不同，spatial attention主要关注于位置信息(where)。为了计算spatial attention，论文首先在channel的维度上使用最大池化和平均池化得到两个不同的特征描述和，然后使用concatenation将两个特征描述合并，并使用卷积操作生成spatial attention map %20%5Cin%20%5Cmathbb%20R_%7BH*W%7D)。计算过程如下： 其中，表示7*7的卷积层 下图为channel attention和spatial attention的示意图： 部分代码： 12345678910111213141516171819202122232425262728293031323334class ChannelAttention(nn.Module): def __init__(self, in_planes, ratio=16): super(ChannelAttention, self).__init__() self.avg_pool = nn.AdaptiveAvgPool2d(1) self.max_pool = nn.AdaptiveMaxPool2d(1) self.fc1 = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False) self.relu1 = nn.ReLU() self.fc2 = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False) self.sigmoid = nn.Sigmoid() def forward(self, x): avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x)))) max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x)))) out = avg_out + max_out return self.sigmoid(out)class SpatialAttention(nn.Module): def __init__(self, kernel_size=7): super(SpatialAttention, self).__init__() assert kernel_size in (3, 7), 'kernel size must be 3 or 7' padding = 3 if kernel_size == 7 else 1 self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False) self.sigmoid = nn.Sigmoid() def forward(self, x): avg_out = torch.mean(x, dim=1, keepdim=True) max_out, _ = torch.max(x, dim=1, keepdim=True) x = torch.cat([avg_out, max_out], dim=1) x = self.conv1(x) return self.sigmoid(x)","categories":[{"name":"CNN","slug":"CNN","permalink":"http://github.com/Bingevan/categories/CNN/"}],"tags":[]},{"title":"hexo基本使用","slug":"hexo基本使用","date":"2019-03-14T11:26:33.000Z","updated":"2019-05-15T12:04:51.516Z","comments":true,"path":"2019/03/14/hexo基本使用/","link":"","permalink":"http://github.com/Bingevan/2019/03/14/hexo基本使用/","excerpt":"","text":"创建新的文章1hexo n 文章的名字 服务器的开启123hexo clearhexo ghexo s 服务器的关闭1ctrl + c 新建分类页与标签页 分类页 1hexo n page categories 标签页 1hexo n page tags 修改完章连接的样式 打开文件：..\\themes\\source\\css_common\\components\\post\\post.styl 12345678//输入代码.post-body p a &#123; color: #345; border-bottom: none; &amp;:hover&#123; color: red; &#125;&#125; 修改文章底部带#号的标签如： 打开文件 ：..\\themes\\next\\layout_macro\\post.swig 修改代码 123456789&lt;footer class=&quot;post-footer&quot;&gt; &#123;% if post.tags and post.tags.length and not is_index %&#125; &lt;div class=&quot;post-tags&quot;&gt; &#123;% for tag in post.tags %&#125; &lt;a href=&quot;&#123;&#123; url_for(tag.path) &#125;&#125;&quot; rel=&quot;tag&quot;&gt;&lt;i class=&quot;fa fa-google&quot;&gt;&lt;/i&gt; &#123;&#123; tag.name &#125;&#125;&lt;/a&gt; &#123;% endfor %&#125; &lt;/div&gt; &#123;% endif %&#125; ... 修改后的样式： 添加Valine评论功能增加搜索功能 打开主题、站点的配置文件 打开官网，找到第三方服务集成，找到搜索服务选择搜索样式： http://theme-next.iissnan.com/third-party-services.html#local-search 在git输入npm install hexo-generator-searchdb --save 编辑主题配置文件 123# Local searchlocal_search: enable: true 添加站点配置文件 12345search: path: search.xml field: post format: html limit: 10000 效果如图： 添加不蒜子统计功能 打开主题的配置文件 打开官网，找到第三方服务集成，找到统计服务经行修改 http://theme-next.iissnan.com/third-party-services.html#analytics-busuanzi 增加分享功能 打开主题的配置文件 找到baidushare修改代码 123baidushare: type: button baidushare: true 隐藏底部的强力驱动 注释掉代码段 1234567891011121314151617&lt;!--&#123;% if theme.footer.powered.enable %&#125; &lt;div class=\"powered-by\"&gt;&#123;# #&#125;&#123;&#123; __('footer.powered', next_url('https://hexo.io', 'Hexo', &#123;class: 'theme-link'&#125;)) &#125;&#125;&#123;# #&#125;&#123;% if theme.footer.powered.version %&#125; v&#123;&#123; hexo_env('version') &#125;&#125;&#123;% endif %&#125;&#123;# #&#125;&lt;/div&gt;&#123;% endif %&#125;&#123;% if theme.footer.powered.enable and theme.footer.theme.enable %&#125; &lt;span class=\"post-meta-divider\"&gt;|&lt;/span&gt;&#123;% endif %&#125;&#123;% if theme.footer.theme.enable %&#125; &lt;div class=\"theme-info\"&gt;&#123;# #&#125;&#123;&#123; __('footer.theme') &#125;&#125; – &#123;&#123; next_url('https://theme-next.org', 'NexT.' + theme.scheme, &#123;class: 'theme-link'&#125;) &#125;&#125;&#123;# #&#125;&#123;% if theme.footer.theme.version %&#125; v&#123;&#123; version &#125;&#125;&#123;% endif %&#125;&#123;##&#125;&lt;/div&gt;&#123;% endif %&#125;--&gt; 实现字数统计与阅读时长功能","categories":[{"name":"工具","slug":"工具","permalink":"http://github.com/Bingevan/categories/工具/"}],"tags":[{"name":"导航","slug":"导航","permalink":"http://github.com/Bingevan/tags/导航/"},{"name":"分享","slug":"分享","permalink":"http://github.com/Bingevan/tags/分享/"}]}]}