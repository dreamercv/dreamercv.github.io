<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> CBAM · Binge.van</title><meta name="description" content="CBAM - 范斌"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/Bingevan/favicon.png"><link rel="stylesheet" href="/Bingevan/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://github.com/Bingevan/atom.xml" title="Binge.van"></head><body><div class="wrap"><header><a href="/Bingevan/" class="logo-link"><img src="/Bingevan/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/Bingevan/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/Bingevan/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="http://weibo.com/sunchongsheng" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://github.com/pinggod" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/Bingevan/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">CBAM</h1><div class="post-info">2019年3月16日</div><div class="post-content"><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><ul>
<li>CBAM特点就是轻量级通用模块</li>
<li>可以很好的加入到CNN结构中</li>
<li>端到端可训练的CNNs</li>
</ul>
<meta name="referrer" content="no-referrer"> 

<a id="more"></a> 
<h3 id="作者贡献"><a href="#作者贡献" class="headerlink" title="作者贡献"></a>作者贡献</h3><ul>
<li>提出了一个高效的attention模块—-CBAM，该模块能够嵌入到目前的主流CNN网络结构中。</li>
<li>通过额外的分离实验证明了CBAM中attention的有效性。</li>
<li>在多个平台上（ImageNet-1K，MS COCO和VOC 2007）上证明了CBAM的性能提升。</li>
</ul>
<h3 id="Convolutional-Block-Attention-Module"><a href="#Convolutional-Block-Attention-Module" class="headerlink" title="Convolutional Block Attention Module"></a>Convolutional Block Attention Module</h3><p>给定输入特征为</p>
<p>对于一个中间层的feature map：<img src="https://math.jianshu.com/math?formula=F%20%5Cin%5Cmathbb%20R%5E%7BC*H*W%7D" alt="F \in\mathbb R^{C*H*W}">，CBAM将会顺序推理出1维的channel attention map <img src="https://math.jianshu.com/math?formula=M_c%20%5Cin%5Cmathbb%20R%5E%7BC*1*1%7D" alt="M_c \in\mathbb R^{C*1*1}">以及2维的spatial attention map <img src="https://math.jianshu.com/math?formula=M_s%20%5Cin%5Cmathbb%20R%5E%7B1*H*W%7D" alt="M_s \in\mathbb R^{1*H*W}">，整个过程如下所示：</p>
<p> <img src="https://math.jianshu.com/math?formula=F%5E%7B%27%7D%20%3D%20M_c(F" alt="F^{&#39;} = M_c(F) \otimes F">%20%5Cotimes%20F)</p>
<p> <img src="https://math.jianshu.com/math?formula=F%5E%7B%27%27%7D%3DM_s(F%5E%7B%27%7D" alt="F^{&#39;&#39;}=M_s(F^{&#39;}) \otimes F^{&#39;}">%20%5Cotimes%20F%5E%7B%27%7D)  </p>
<p>其中<img src="https://math.jianshu.com/math?formula=%5Cotimes" alt="\otimes">为element-wise multiplication，首先将channel attention map与输入的feature map相乘得到<img src="https://math.jianshu.com/math?formula=F%5E%7B%27%7D" alt="F^{&#39;}">，之后计算<img src="https://math.jianshu.com/math?formula=F%5E%7B%27%7D" alt="F^{&#39;}">的spatial attention map，并将两者相乘得到最终的输出<img src="https://math.jianshu.com/math?formula=F%5E%7B%27%27%7D" alt="F^{&#39;&#39;}">。下图为CBAM的示意图： </p>
<p><img src="http://prjlqbksp.bkt.clouddn.com/blog/20190515/0A3Rcv6utKj4.png?imageslim" alt="mark"></p>
<h4 id="Channel-attention-module"><a href="#Channel-attention-module" class="headerlink" title="Channel attention module"></a>Channel attention module</h4><p>eature map 的每个channel都被视为一个feature detector，channel attention主要关注于输入图片中什么(<strong>what</strong>)是有意义的。为了高效地计算channel attention，论文使用<strong>最大池化</strong>和<strong>平均池化</strong>对feature map在空间维度上进行压缩，得到两个不同的空间背景描述：<img src="https://math.jianshu.com/math?formula=F%5E%7Bc%7D_%7Bmax%7D" alt="F^{c}_{max}">和<img src="https://math.jianshu.com/math?formula=F%5E%7Bc%7D_%7Bavg%7D" alt="F^{c}_{avg}">。使用由MLP组成的共享网络对这两个不同的空间背景描述进行计算得到channel attention map：<img src="https://math.jianshu.com/math?formula=M_c%20%5Cin%5Cmathbb%20R%5E%7BC*1*1%7D" alt="M_c \in\mathbb R^{C*1*1}">。计算过程如下：<br><img src="http://prjlqbksp.bkt.clouddn.com/blog/20190515/kWCjiUIW95Sq.png?imageslim" alt="mark"></p>
<p>其中<img src="https://math.jianshu.com/math?formula=W_0%20%5Cin%20%5Cmathbb%20R%5E%7BC%2Fr%20*%20C%7D" alt="W_0 \in \mathbb R^{C/r * C}">，<img src="https://math.jianshu.com/math?formula=W_1%20%5Cin%20%5Cmathbb%20R%5E%7BC%20*%20C%2Fr%7D" alt="W_1 \in \mathbb R^{C * C/r}">，<img src="https://math.jianshu.com/math?formula=W_0" alt="W_0">后使用了Relu作为激活函数。</p>
<h4 id="Spatial-attention-module"><a href="#Spatial-attention-module" class="headerlink" title="Spatial attention module."></a>Spatial attention module.</h4><p> 与channel attention不同，spatial attention主要关注于位置信息(where)。为了计算spatial attention，论文首先在channel的维度上使用<strong>最大池化</strong>和<strong>平均池化</strong>得到两个不同的特征描述<img src="https://math.jianshu.com/math?formula=F%5E%7Bs%7D_%7Bmax%7D%20%5Cin%20%5Cmathbb%20R_%7B1*H*W%7D" alt="F^{s}_{max} \in \mathbb R_{1*H*W}">和<img src="https://math.jianshu.com/math?formula=F%5E%7Bs%7D_%7Bavg%7D%20%5Cin%20%5Cmathbb%20R_%7B1*H*W%7D" alt="F^{s}_{avg} \in \mathbb R_{1*H*W}">，然后使用concatenation将两个特征描述合并，并使用卷积操作生成spatial attention map <img src="https://math.jianshu.com/math?formula=M_s(F" alt="M_s(F) \in \mathbb R_{H*W}">%20%5Cin%20%5Cmathbb%20R_%7BH*W%7D)。计算过程如下：</p>
<p><img src="http://prjlqbksp.bkt.clouddn.com/blog/20190515/fr6wil28wJb6.png?imageslim" alt="mark"></p>
<p>其中，<img src="https://math.jianshu.com/math?formula=f%5E%7B7*7%7D" alt="f^{7*7}">表示7*7的卷积层</p>
<p>下图为channel attention和spatial attention的示意图：</p>
<p><img src="http://prjlqbksp.bkt.clouddn.com/blog/20190515/CcPnHmdQjmzC.png?imageslim" alt="mark"></p>
<p> 部分代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChannelAttention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_planes, ratio=<span class="number">16</span>)</span>:</span></span><br><span class="line">        super(ChannelAttention, self).__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        self.max_pool = nn.AdaptiveMaxPool2d(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.fc1   = nn.Conv2d(in_planes, in_planes // <span class="number">16</span>, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line">        self.fc2   = nn.Conv2d(in_planes // <span class="number">16</span>, in_planes, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))</span><br><span class="line">        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))</span><br><span class="line">        out = avg_out + max_out</span><br><span class="line">        <span class="keyword">return</span> self.sigmoid(out)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpatialAttention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, kernel_size=<span class="number">7</span>)</span>:</span></span><br><span class="line">        super(SpatialAttention, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> kernel_size <span class="keyword">in</span> (<span class="number">3</span>, <span class="number">7</span>), <span class="string">'kernel size must be 3 or 7'</span></span><br><span class="line">        padding = <span class="number">3</span> <span class="keyword">if</span> kernel_size == <span class="number">7</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">2</span>, <span class="number">1</span>, kernel_size, padding=padding, bias=<span class="literal">False</span>)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        avg_out = torch.mean(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        max_out, _ = torch.max(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        x = torch.cat([avg_out, max_out], dim=<span class="number">1</span>)</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> self.sigmoid(x)</span><br></pre></td></tr></table></figure>
</div></article></div></main><footer><div class="paginator"><a href="/Bingevan/2019/03/17/深度学习/" class="prev">上一篇</a><a href="/Bingevan/2019/03/14/hexo基本使用/" class="next">下一篇</a></div><div class="copyright"><p>© 2015 - 2019 <a href="http://github.com/Bingevan">范斌</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>