<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> MobileNetV1 · Binge.van</title><meta name="description" content="MobileNetV1 - 范斌"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/Bingevan/favicon.png"><link rel="stylesheet" href="/Bingevan/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://github.com/Bingevan/atom.xml" title="Binge.van"></head><body><div class="wrap"><header><a href="/Bingevan/" class="logo-link"><img src="/Bingevan/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/Bingevan/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/Bingevan/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="http://weibo.com/sunchongsheng" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://github.com/pinggod" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/Bingevan/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">MobileNetV1</h1><div class="post-info">2019年5月10日</div><div class="post-content"><meta name="referrer" content="no-referrer"> 

<a id="more"></a> 
<h2 id="MobileNetV1"><a href="#MobileNetV1" class="headerlink" title="MobileNetV1"></a>MobileNetV1</h2><blockquote>
<ul>
<li>《MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications 》</li>
<li>The paper address：<a href="https://arxiv.org/abs/1704.04861" target="_blank" rel="noopener">https://arxiv.org/abs/1704.04861</a></li>
<li>The coding address：<a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.py">https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.py</a> </li>
</ul>
</blockquote>
<h2 id="WWH（What-amp-Why-amp-How）"><a href="#WWH（What-amp-Why-amp-How）" class="headerlink" title="WWH（What&amp;Why&amp;How）"></a>WWH（What&amp;Why&amp;How）</h2><p>​    MobileNet描述了一个高效的网络架构，可以构建一个非常小、低延时、满足嵌入式设备的要求。模型的大小显著下降，但是实际效果很好。</p>
<h2 id="Innovation-Points"><a href="#Innovation-Points" class="headerlink" title="Innovation Points"></a>Innovation Points</h2><ul>
<li>深度可分离卷积（Depthwise Separable Convolution）</li>
<li>宽度因子（Width Multiplier）&amp; 分辨率因子（Resolution Multiplier）</li>
</ul>
<h2 id="Depthwise-Separable-Convolution"><a href="#Depthwise-Separable-Convolution" class="headerlink" title="Depthwise Separable Convolution"></a>Depthwise Separable Convolution</h2><blockquote>
<p>深度可分离卷积：将普通卷积分成深度卷积（DW）与逐点卷积（PW），这样做可大幅度降低参数量与计算量。</p>
</blockquote>
<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><ul>
<li>Depthwise Separable Convolution与普通卷积的输入与输出均相同，中间过程不同。</li>
<li>输入： <img src="https://www.zhihu.com/equation?tex=D_F+%5Ccdot+D_F+%5Ccdot+M" alt="D_F \cdot D_F \cdot M"> ，其中 <img src="https://www.zhihu.com/equation?tex=D_F+" alt="D_F "> 为原始图片尺寸， <img src="https://www.zhihu.com/equation?tex=M+" alt="M "> 为输入channel数量。</li>
<li>输出： <img src="https://www.zhihu.com/equation?tex=D_F+%5Ccdot+D_F+%5Ccdot+N" alt="D_F \cdot D_F \cdot N"> ，其中 <img src="https://www.zhihu.com/equation?tex=D_F" alt="D_F"> 为输出图片尺寸， <img src="https://www.zhihu.com/equation?tex=N" alt="N"> 为输出channel数量。</li>
</ul>
<h3 id="普通卷积"><a href="#普通卷积" class="headerlink" title="普通卷积"></a>普通卷积</h3><ul>
<li>卷积核： <img src="https://www.zhihu.com/equation?tex=D_K+%5Ccdot+D_K+%5Ccdot+M+%5Ccdot+N" alt="D_K \cdot D_K \cdot M \cdot N"></li>
</ul>
<p>卷积核如下图所示：</p>
<p><img src="http://prjlqbksp.bkt.clouddn.com/blog/20190515/pm3lMnX21nAW.jpg?imageslim" alt="mark"></p>
<h3 id="深度可分离卷积"><a href="#深度可分离卷积" class="headerlink" title="深度可分离卷积"></a>深度可分离卷积</h3><h4 id="深度卷积"><a href="#深度卷积" class="headerlink" title="深度卷积"></a>深度卷积</h4><ul>
<li>输入： <img src="https://www.zhihu.com/equation?tex=D_F+%5Ccdot+D_F+%5Ccdot+M" alt="D_F \cdot D_F \cdot M"> ，输出 <img src="https://www.zhihu.com/equation?tex=D_F+%5Ccdot+D_F+%5Ccdot+M" alt="D_F \cdot D_F \cdot M"> </li>
<li>卷积核：M个 <img src="https://www.zhihu.com/equation?tex=D_K+%5Ccdot+D_K+%5Ccdot+1+%5Ccdot+1" alt="D_K \cdot D_K \cdot 1 \cdot 1"> 。 </li>
</ul>
<p><img src="http://prjlqbksp.bkt.clouddn.com/blog/20190515/lNf7mYyUTBUH.jpg?imageslim" alt="mark"></p>
<ul>
<li>理解：<ul>
<li>将特征图看成是M张二维的特征图即M张 <img src="https://www.zhihu.com/equation?tex=D_F+%5Ccdot+D_F+%5Ccdot+1" alt="D_F \cdot D_F \cdot 1"> 的特征图</li>
<li>将M张特征图分别与   <img src="https://www.zhihu.com/equation?tex=D_K+%5Ccdot+D_K+%5Ccdot+1+%5Ccdot+1" alt="D_K \cdot D_K \cdot 1 \cdot 1">的卷积核卷积</li>
<li>也就是对channel进行分解</li>
</ul>
</li>
</ul>
<h4 id="逐点卷积"><a href="#逐点卷积" class="headerlink" title="逐点卷积"></a>逐点卷积</h4><ul>
<li>输入 <img src="https://www.zhihu.com/equation?tex=D_F+%5Ccdot+D_F+%5Ccdot+M" alt="D_F \cdot D_F \cdot M"> ，输出 <img src="https://www.zhihu.com/equation?tex=D_F+%5Ccdot+D_F+%5Ccdot+N" alt="D_F \cdot D_F \cdot N">。</li>
<li>卷积核： <img src="https://www.zhihu.com/equation?tex=1+%5Ccdot+1+%5Ccdot+M+%5Ccdot+N" alt="1 \cdot 1 \cdot M \cdot N"> 。</li>
</ul>
<p><img src="http://prjlqbksp.bkt.clouddn.com/blog/20190515/TEdXDOX8i8Nx.jpg?imageslim" alt="mark"></p>
<h3 id="计算量对比"><a href="#计算量对比" class="headerlink" title="计算量对比"></a>计算量对比</h3><p>分子为Depthwise Separable卷积，分母为普通卷积。</p>
<p><img src="http://prjlqbksp.bkt.clouddn.com/blog/20190515/eUsHaH893UjN.jpg?imageslim" alt="mark"></p>
<blockquote>
<p>深度可分离卷积与标准卷积相比：当采用3x3的卷积核，计算量可以减少9倍左右</p>
</blockquote>
<h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p><img src="http://prjlqbksp.bkt.clouddn.com/blog/20190515/IhYSBvuXU1IX.png?imageslim" alt="mark"></p>
<blockquote>
<p><strong>注意：如果是需要下采样，则在第一个深度卷积上取步长为2.</strong> </p>
</blockquote>
<h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Block</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">'''Depthwise conv + Pointwise conv'''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_planes, out_planes, stride=<span class="number">1</span>)</span>:</span></span><br><span class="line">        super(Block, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d\</span><br><span class="line">            (in_planes, in_planes, kernel_size=<span class="number">3</span>, stride=stride, </span><br><span class="line">             padding=<span class="number">1</span>, groups=in_planes, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(in_planes)</span><br><span class="line">        self.conv2 = nn.Conv2d\</span><br><span class="line">            (in_planes, out_planes, kernel_size=<span class="number">1</span>, </span><br><span class="line">            stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(out_planes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        out = F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        out = F.relu(self.bn2(self.conv2(out)))</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h3 id="MobileNetV1网络"><a href="#MobileNetV1网络" class="headerlink" title="MobileNetV1网络"></a>MobileNetV1网络</h3><h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p><img src="http://prjlqbksp.bkt.clouddn.com/blog/20190515/IymI6uKwl1s0.jpg?imageslim" alt="mark"></p>
<h4 id="网络介绍"><a href="#网络介绍" class="headerlink" title="网络介绍"></a>网络介绍</h4><ul>
<li><p>MobileNet优化的重点放在优化延迟(latency)，兼顾模型大小。</p>
</li>
<li><p>网络参数、计算量分布：</p>
<p><img src="http://prjlqbksp.bkt.clouddn.com/blog/20190515/hAXIQgK2YqOR.jpg?imageslim" alt="mark"></p>
</li>
<li><p>MobileNet中大多数计算量和参数都在1*1的卷积中，可以使用高度优化的。</p>
</li>
<li><p>由于模型较小，所以可以减少使用正则化，因为模型小不容易过拟合。</p>
</li>
</ul>
<h2 id="Width-Multiplier-amp-Resolution-Multiplier"><a href="#Width-Multiplier-amp-Resolution-Multiplier" class="headerlink" title="Width Multiplier&amp;Resolution Multiplier"></a>Width Multiplier&amp;Resolution Multiplier</h2><h3 id="Width-Multiplier-："><a href="#Width-Multiplier-：" class="headerlink" title="Width Multiplier,  ："></a>Width Multiplier, <img src="https://www.zhihu.com/equation?tex=%5Calpha+" alt="\alpha "> ：</h3><ul>
<li>用于控制输入和输出的通道数，即输入通道从M 变为αM ,输出通道从N变为αN。</li>
</ul>
<ul>
<li>对于depthwise卷积操作，其计算量为：</li>
</ul>
<p><img src="http://prjlqbksp.bkt.clouddn.com/blog/20190515/NULKYEUyz6U3.jpg?imageslim" alt="mark"></p>
<ul>
<li>可设置α∈(0,1]，通常取1,0.75,0.5和0.25 。</li>
</ul>
<h3 id="Resolution-Multiplier，"><a href="#Resolution-Multiplier，" class="headerlink" title="Resolution Multiplier， "></a>Resolution Multiplier， <img src="https://www.zhihu.com/equation?tex=%5Crho" alt="\rho"></h3><ul>
<li>用于控制输入和内部层表示。即用分辨率因子控制输入的分辨率，该参数用于控制特征图的宽和高 。</li>
<li>对于depthwise卷积操作，其计算量为：  </li>
</ul>
<p><img src="http://prjlqbksp.bkt.clouddn.com/blog/20190515/O0IwIFhLVn9R.jpg?imageslim" alt="mark"></p>
<ul>
<li>可设置ρ∈(0,1]，通常设置输入分辨率为224,192,160和128 </li>
</ul>
<p><img src="http://prjlqbksp.bkt.clouddn.com/blog/20190515/hXgKqRaTixGz.jpg?imageslim" alt="mark"></p>
</div></article></div></main><footer><div class="paginator"><a href="/Bingevan/2019/05/10/MobileNetV2/" class="next">下一篇</a></div><div class="copyright"><p>© 2015 - 2019 <a href="http://github.com/Bingevan">范斌</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>